{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goutamkumar08/GenAI/blob/main/Semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing important Libraries"
      ],
      "metadata": {
        "id": "_rj8TA60QgYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r31RzKbYPCEw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing FAISS, importing models, using NumPy."
      ],
      "metadata": {
        "id": "2tPvLfEIRaNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "import faiss\n",
        "from torchvision import models\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nth1SoreP7zd",
        "outputId": "b25ca94f-31b5-4c80-8a85-f420a3524fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrape, filter, extract, index, search."
      ],
      "metadata": {
        "id": "GMCxiRSIRudw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_images(url, output_folder=\"images\"):\n",
        "    \"\"\"Scrapes images from a webpage and saves them.\"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True) # Create the output folder if it does not exist\n",
        "    response = requests.get(url)   # Send an HTTP request to fetch the webpage content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    img_tags = soup.find_all('img')  # Find all image tags in the webpage\n",
        "\n",
        "    images = []\n",
        "    for i, img_tag in enumerate(img_tags):\n",
        "        img_url = img_tag.get('src')\n",
        "        if img_url and img_url.startswith(('http', 'https')):  # Ensure the image URL is valid and has a proper format\n",
        "            try:\n",
        "                img_data = requests.get(img_url).content    # Fetch image content\n",
        "                img_path = os.path.join(output_folder, f\"image_{i}.jpg\")   # Define the path to save the image\n",
        "                with open(img_path, 'wb') as f:   # Save the image to the local folder\n",
        "                    f.write(img_data)\n",
        "                images.append(img_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {img_url}: {e}\") # handling download errors\n",
        "    return images\n",
        "\n",
        "def is_advertisement(image_path):\n",
        "    \"\"\"Placeholder function to detect ads based on image size or content.\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    if img.size[0] * img.size[1] < 5000:  #  Remove very small images\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def filter_images(image_paths):\n",
        "    \"\"\"Removes images classified as advertisements.\"\"\"\n",
        "    return [img for img in image_paths if not is_advertisement(img)]\n",
        "\n",
        "def extract_features(image_paths):\n",
        "    \"\"\"Extracts embeddings using a pretrained ResNet model.\"\"\"\n",
        "    model = models.resnet50(pretrained=True) # load ResNet-50 model\n",
        "    model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
        "    model.eval()\n",
        "\n",
        " # Define the image preprocessing transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)), # resizing to match ResNet input size\n",
        "        transforms.ToTensor(), # converting images to tensor\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    features = []\n",
        "    for image_path in image_paths:\n",
        "        img = Image.open(image_path).convert('RGB')  # ensure image is in RGB format\n",
        "        img = transform(img).unsqueeze(0)\n",
        "        with torch.no_grad(): # Disable gradient computation for efficiency\n",
        "            feature = model(img).squeeze().numpy()\n",
        "        features.append(feature)\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "def create_faiss_index(features):\n",
        "    \"\"\"Creates a FAISS index for semantic search.\"\"\"\n",
        "    d = features.shape[1] #getting feature dimension size\n",
        "    index = faiss.IndexFlatL2(d) # L2 (euclidean) distance- based index\n",
        "    index.add(features) # adding feature vector to the index\n",
        "    return index\n",
        "\n",
        "def search_images(query_image, image_paths, index):\n",
        "    \"\"\"Finds similar images using FAISS semantic search.\"\"\"\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model = torch.nn.Sequential(*(list(model.children())[:-1]))  # Remove FC layer\n",
        "    model.eval()\n",
        "\n",
        "# Define preprocessing transformations for the query image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "   # loading and preprocessing the query image\n",
        "    img = Image.open(query_image).convert('RGB')\n",
        "    img = transform(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        query_feature = model(img).squeeze().numpy()\n",
        "\n",
        "  # Reshape the feature vector to match FAISS input requirements\n",
        "    query_feature = np.expand_dims(query_feature, axis=0).astype('float32')\n",
        "\n",
        "    assert query_feature.shape[1] == index.d, f\"Query feature dimension {query_feature.shape[1]} does not match FAISS index dimension {index.d}\"\n",
        "\n",
        "    _, indices = index.search(query_feature, 5)  # Return top 5 results\n",
        "    return [image_paths[i] for i in indices[0]]\n",
        "\n"
      ],
      "metadata": {
        "id": "EFk-WrroQftS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HT9gu5iaQerI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    website_url = \"https://www.amazon.in/\"\n",
        "    images = scrape_images(website_url)\n",
        "    filtered_images = filter_images(images)\n",
        "    features = extract_features(filtered_images)\n",
        "    index = create_faiss_index(features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZ_FJwjQuoO",
        "outputId": "15968c5b-493c-42bd-d3e3-3a523c5d43b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAoRAocoRgay",
        "outputId": "41649a97-c9b0-4028-cb2c-51cb0d0763fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['images/image_0.jpg',\n",
              " 'images/image_1.jpg',\n",
              " 'images/image_2.jpg',\n",
              " 'images/image_3.jpg',\n",
              " 'images/image_4.jpg',\n",
              " 'images/image_5.jpg',\n",
              " 'images/image_6.jpg',\n",
              " 'images/image_7.jpg',\n",
              " 'images/image_8.jpg',\n",
              " 'images/image_9.jpg',\n",
              " 'images/image_10.jpg',\n",
              " 'images/image_11.jpg',\n",
              " 'images/image_12.jpg',\n",
              " 'images/image_13.jpg',\n",
              " 'images/image_14.jpg',\n",
              " 'images/image_15.jpg',\n",
              " 'images/image_16.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_img =\"/content/query_images/query_image.jpeg\"\n",
        "similar_images = search_images(query_img, filtered_images, index)\n",
        "print(\"Similar images:\", similar_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F933kWnVOk-",
        "outputId": "ee9319d4-82bd-4f25-f545-df9184ed5424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar images: ['images/image_15.jpg', 'images/image_0.jpg', 'images/image_6.jpg', 'images/image_11.jpg', 'images/image_8.jpg']\n"
          ]
        }
      ]
    }
  ]
}